{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Design"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to design our solution to attain a model that can predict a customer BER rating through classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Pre Model Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import graphviz\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn import metrics\n",
    "import random\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "\n",
    "random.seed(2814)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in our cleaned up SEAI data\n",
    "seai_dropped_na = pd.read_csv('../data/interim/1_seai_dropped_na.csv')\n",
    "seai_dropped_na = seai_dropped_na.drop('BerRating', axis = 1)\n",
    "seai_dropped_na = seai_dropped_na.drop('CO2Rating', axis = 1)\n",
    "seai_dropped_na['NoOfSidesSheltered'] = seai_dropped_na['NoOfSidesSheltered'].astype('category')\n",
    "new_cols = [col for col in seai_dropped_na.columns if col != 'EnergyRating'] + ['EnergyRating']\n",
    "seai_dropped_na = seai_dropped_na[new_cols]\n",
    "\n",
    "del(new_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CountyName</th>\n",
       "      <th>DwellingTypeDescr</th>\n",
       "      <th>YearofConstruction</th>\n",
       "      <th>GroundFloorArea(sq m)</th>\n",
       "      <th>MainSpaceHeatingFuel</th>\n",
       "      <th>MainWaterHeatingFuel</th>\n",
       "      <th>VentilationMethod</th>\n",
       "      <th>StructureType</th>\n",
       "      <th>NoOfSidesSheltered</th>\n",
       "      <th>InsulationType</th>\n",
       "      <th>InsulationThickness</th>\n",
       "      <th>TotalDeliveredEnergy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EnergyRating</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A1</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2</th>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3</th>\n",
       "      <td>865</td>\n",
       "      <td>865</td>\n",
       "      <td>865</td>\n",
       "      <td>865</td>\n",
       "      <td>865</td>\n",
       "      <td>865</td>\n",
       "      <td>865</td>\n",
       "      <td>865</td>\n",
       "      <td>865</td>\n",
       "      <td>865</td>\n",
       "      <td>865</td>\n",
       "      <td>865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B1</th>\n",
       "      <td>2608</td>\n",
       "      <td>2608</td>\n",
       "      <td>2608</td>\n",
       "      <td>2608</td>\n",
       "      <td>2608</td>\n",
       "      <td>2608</td>\n",
       "      <td>2608</td>\n",
       "      <td>2608</td>\n",
       "      <td>2608</td>\n",
       "      <td>2608</td>\n",
       "      <td>2608</td>\n",
       "      <td>2608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B2</th>\n",
       "      <td>7385</td>\n",
       "      <td>7385</td>\n",
       "      <td>7385</td>\n",
       "      <td>7385</td>\n",
       "      <td>7385</td>\n",
       "      <td>7385</td>\n",
       "      <td>7385</td>\n",
       "      <td>7385</td>\n",
       "      <td>7385</td>\n",
       "      <td>7385</td>\n",
       "      <td>7385</td>\n",
       "      <td>7385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B3</th>\n",
       "      <td>19648</td>\n",
       "      <td>19648</td>\n",
       "      <td>19648</td>\n",
       "      <td>19648</td>\n",
       "      <td>19648</td>\n",
       "      <td>19648</td>\n",
       "      <td>19648</td>\n",
       "      <td>19648</td>\n",
       "      <td>19648</td>\n",
       "      <td>19648</td>\n",
       "      <td>19648</td>\n",
       "      <td>19648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C1</th>\n",
       "      <td>34849</td>\n",
       "      <td>34849</td>\n",
       "      <td>34849</td>\n",
       "      <td>34849</td>\n",
       "      <td>34849</td>\n",
       "      <td>34849</td>\n",
       "      <td>34849</td>\n",
       "      <td>34849</td>\n",
       "      <td>34849</td>\n",
       "      <td>34849</td>\n",
       "      <td>34849</td>\n",
       "      <td>34849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C2</th>\n",
       "      <td>47825</td>\n",
       "      <td>47825</td>\n",
       "      <td>47825</td>\n",
       "      <td>47825</td>\n",
       "      <td>47825</td>\n",
       "      <td>47825</td>\n",
       "      <td>47825</td>\n",
       "      <td>47825</td>\n",
       "      <td>47825</td>\n",
       "      <td>47825</td>\n",
       "      <td>47825</td>\n",
       "      <td>47825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C3</th>\n",
       "      <td>53588</td>\n",
       "      <td>53588</td>\n",
       "      <td>53588</td>\n",
       "      <td>53588</td>\n",
       "      <td>53588</td>\n",
       "      <td>53588</td>\n",
       "      <td>53588</td>\n",
       "      <td>53588</td>\n",
       "      <td>53588</td>\n",
       "      <td>53588</td>\n",
       "      <td>53588</td>\n",
       "      <td>53588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D1</th>\n",
       "      <td>55284</td>\n",
       "      <td>55284</td>\n",
       "      <td>55284</td>\n",
       "      <td>55284</td>\n",
       "      <td>55284</td>\n",
       "      <td>55284</td>\n",
       "      <td>55284</td>\n",
       "      <td>55284</td>\n",
       "      <td>55284</td>\n",
       "      <td>55284</td>\n",
       "      <td>55284</td>\n",
       "      <td>55284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D2</th>\n",
       "      <td>48914</td>\n",
       "      <td>48914</td>\n",
       "      <td>48914</td>\n",
       "      <td>48914</td>\n",
       "      <td>48914</td>\n",
       "      <td>48914</td>\n",
       "      <td>48914</td>\n",
       "      <td>48914</td>\n",
       "      <td>48914</td>\n",
       "      <td>48914</td>\n",
       "      <td>48914</td>\n",
       "      <td>48914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E1</th>\n",
       "      <td>28575</td>\n",
       "      <td>28575</td>\n",
       "      <td>28575</td>\n",
       "      <td>28575</td>\n",
       "      <td>28575</td>\n",
       "      <td>28575</td>\n",
       "      <td>28575</td>\n",
       "      <td>28575</td>\n",
       "      <td>28575</td>\n",
       "      <td>28575</td>\n",
       "      <td>28575</td>\n",
       "      <td>28575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E2</th>\n",
       "      <td>23701</td>\n",
       "      <td>23701</td>\n",
       "      <td>23701</td>\n",
       "      <td>23701</td>\n",
       "      <td>23701</td>\n",
       "      <td>23701</td>\n",
       "      <td>23701</td>\n",
       "      <td>23701</td>\n",
       "      <td>23701</td>\n",
       "      <td>23701</td>\n",
       "      <td>23701</td>\n",
       "      <td>23701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <td>24954</td>\n",
       "      <td>24954</td>\n",
       "      <td>24954</td>\n",
       "      <td>24954</td>\n",
       "      <td>24954</td>\n",
       "      <td>24954</td>\n",
       "      <td>24954</td>\n",
       "      <td>24954</td>\n",
       "      <td>24954</td>\n",
       "      <td>24954</td>\n",
       "      <td>24954</td>\n",
       "      <td>24954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G</th>\n",
       "      <td>30239</td>\n",
       "      <td>30239</td>\n",
       "      <td>30239</td>\n",
       "      <td>30239</td>\n",
       "      <td>30239</td>\n",
       "      <td>30239</td>\n",
       "      <td>30239</td>\n",
       "      <td>30239</td>\n",
       "      <td>30239</td>\n",
       "      <td>30239</td>\n",
       "      <td>30239</td>\n",
       "      <td>30239</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              CountyName  DwellingTypeDescr  YearofConstruction  \\\n",
       "EnergyRating                                                      \n",
       "A1                     3                  3                   3   \n",
       "A2                    71                 71                  71   \n",
       "A3                   865                865                 865   \n",
       "B1                  2608               2608                2608   \n",
       "B2                  7385               7385                7385   \n",
       "B3                 19648              19648               19648   \n",
       "C1                 34849              34849               34849   \n",
       "C2                 47825              47825               47825   \n",
       "C3                 53588              53588               53588   \n",
       "D1                 55284              55284               55284   \n",
       "D2                 48914              48914               48914   \n",
       "E1                 28575              28575               28575   \n",
       "E2                 23701              23701               23701   \n",
       "F                  24954              24954               24954   \n",
       "G                  30239              30239               30239   \n",
       "\n",
       "              GroundFloorArea(sq m)  MainSpaceHeatingFuel  \\\n",
       "EnergyRating                                                \n",
       "A1                                3                     3   \n",
       "A2                               71                    71   \n",
       "A3                              865                   865   \n",
       "B1                             2608                  2608   \n",
       "B2                             7385                  7385   \n",
       "B3                            19648                 19648   \n",
       "C1                            34849                 34849   \n",
       "C2                            47825                 47825   \n",
       "C3                            53588                 53588   \n",
       "D1                            55284                 55284   \n",
       "D2                            48914                 48914   \n",
       "E1                            28575                 28575   \n",
       "E2                            23701                 23701   \n",
       "F                             24954                 24954   \n",
       "G                             30239                 30239   \n",
       "\n",
       "              MainWaterHeatingFuel  VentilationMethod  StructureType  \\\n",
       "EnergyRating                                                           \n",
       "A1                               3                  3              3   \n",
       "A2                              71                 71             71   \n",
       "A3                             865                865            865   \n",
       "B1                            2608               2608           2608   \n",
       "B2                            7385               7385           7385   \n",
       "B3                           19648              19648          19648   \n",
       "C1                           34849              34849          34849   \n",
       "C2                           47825              47825          47825   \n",
       "C3                           53588              53588          53588   \n",
       "D1                           55284              55284          55284   \n",
       "D2                           48914              48914          48914   \n",
       "E1                           28575              28575          28575   \n",
       "E2                           23701              23701          23701   \n",
       "F                            24954              24954          24954   \n",
       "G                            30239              30239          30239   \n",
       "\n",
       "              NoOfSidesSheltered  InsulationType  InsulationThickness  \\\n",
       "EnergyRating                                                            \n",
       "A1                             3               3                    3   \n",
       "A2                            71              71                   71   \n",
       "A3                           865             865                  865   \n",
       "B1                          2608            2608                 2608   \n",
       "B2                          7385            7385                 7385   \n",
       "B3                         19648           19648                19648   \n",
       "C1                         34849           34849                34849   \n",
       "C2                         47825           47825                47825   \n",
       "C3                         53588           53588                53588   \n",
       "D1                         55284           55284                55284   \n",
       "D2                         48914           48914                48914   \n",
       "E1                         28575           28575                28575   \n",
       "E2                         23701           23701                23701   \n",
       "F                          24954           24954                24954   \n",
       "G                          30239           30239                30239   \n",
       "\n",
       "              TotalDeliveredEnergy  \n",
       "EnergyRating                        \n",
       "A1                               3  \n",
       "A2                              71  \n",
       "A3                             865  \n",
       "B1                            2608  \n",
       "B2                            7385  \n",
       "B3                           19648  \n",
       "C1                           34849  \n",
       "C2                           47825  \n",
       "C3                           53588  \n",
       "D1                           55284  \n",
       "D2                           48914  \n",
       "E1                           28575  \n",
       "E2                           23701  \n",
       "F                            24954  \n",
       "G                            30239  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seai_dropped_na.groupby('EnergyRating').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a very imbalanced dataset for our classes which needs to be fixed or or model will be useless"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 Modelling Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal now is to be able to model BER ratings\n",
    "\n",
    "I will break this down into steps:\n",
    "- Chooses algorithms to try\n",
    "    - Logistic Regression\n",
    "    - kNN\n",
    "    - Random Forest\n",
    "    - SVMs\n",
    "    - NNs\n",
    "- Check the preprocessing requirements of each\n",
    "    - Dummy variable encoding (like in the define phase).\n",
    "    - Standardisation of variables .\n",
    "    - Train/Test Split - 70/30."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.1 Scaling the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = QuantileTransformer()\n",
    "num_cols = ['YearofConstruction', 'GroundFloorArea(sq m)', 'TotalDeliveredEnergy', 'InsulationThickness']\n",
    "seai_dropped_na_scaled = seai_dropped_na.copy()\n",
    "seai_dropped_na_scaled[num_cols] = scaler.fit_transform(seai_dropped_na[num_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.2 Encoding the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/a/52935270/5923619\n",
    "# One Hot Encodes our categorical feature and binds it to the original dataset\n",
    "def encode_and_bind(original_dataframe, feature_to_encode):\n",
    "    dummies = pd.get_dummies(original_dataframe[[feature_to_encode]])\n",
    "    res = pd.concat([original_dataframe, dummies], axis=1)\n",
    "    return(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot Encode all of our categorical features\n",
    "seai_dropped_na_scaled = encode_and_bind(seai_dropped_na_scaled, 'CountyName')\n",
    "seai_dropped_na_scaled = encode_and_bind(seai_dropped_na_scaled, 'DwellingTypeDescr')\n",
    "seai_dropped_na_scaled = encode_and_bind(seai_dropped_na_scaled, 'MainSpaceHeatingFuel')\n",
    "seai_dropped_na_scaled = encode_and_bind(seai_dropped_na_scaled, 'MainWaterHeatingFuel')\n",
    "seai_dropped_na_scaled = encode_and_bind(seai_dropped_na_scaled, 'VentilationMethod')\n",
    "seai_dropped_na_scaled = encode_and_bind(seai_dropped_na_scaled, 'StructureType')\n",
    "seai_dropped_na_scaled = encode_and_bind(seai_dropped_na_scaled, 'InsulationType')\n",
    "seai_dropped_na_scaled = encode_and_bind(seai_dropped_na_scaled, 'MainSpaceHeatingFuel')\n",
    "seai_dropped_na_scaled = encode_and_bind(seai_dropped_na_scaled, 'MainWaterHeatingFuel')\n",
    "seai_dropped_na_scaled = encode_and_bind(seai_dropped_na_scaled, 'NoOfSidesSheltered')\n",
    "\n",
    "seai_dropped_na_scaled\n",
    "# Dropping the unencoded columns for now\n",
    "seai_dropped_na_scaled = seai_dropped_na_scaled.drop(['CountyName', 'DwellingTypeDescr', 'VentilationMethod', 'StructureType', 'InsulationType', 'MainSpaceHeatingFuel',\t'MainWaterHeatingFuel',\t'NoOfSidesSheltered'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cols = [col for col in seai_dropped_na_scaled.columns if col != 'EnergyRating'] + ['EnergyRating']\n",
    "seai_dropped_na_scaled = seai_dropped_na_scaled[new_cols]\n",
    "\n",
    "del(new_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = seai_dropped_na_scaled.iloc[:, :-1] # Independent Variables\n",
    "y = seai_dropped_na_scaled.iloc[:, -1] # Dependent Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "D1    55284\n",
       "C3    53588\n",
       "D2    48914\n",
       "C2    47825\n",
       "C1    34849\n",
       "G     30239\n",
       "E1    28575\n",
       "F     24954\n",
       "E2    23701\n",
       "B3    19648\n",
       "B2     7385\n",
       "B1     2608\n",
       "A3      865\n",
       "A2       71\n",
       "A1        3\n",
       "Name: EnergyRating, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/oisinbrannock/Documents/masters_thesis_ob2814/masters_thesis/notebooks/design-classificationv2.ipynb Cell 20\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/oisinbrannock/Documents/masters_thesis_ob2814/masters_thesis/notebooks/design-classificationv2.ipynb#ch0000019?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mimblearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mover_sampling\u001b[39;00m \u001b[39mimport\u001b[39;00m SMOTE\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/oisinbrannock/Documents/masters_thesis_ob2814/masters_thesis/notebooks/design-classificationv2.ipynb#ch0000019?line=1'>2</a>\u001b[0m oversample \u001b[39m=\u001b[39m SMOTE(k_neighbors\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/oisinbrannock/Documents/masters_thesis_ob2814/masters_thesis/notebooks/design-classificationv2.ipynb#ch0000019?line=2'>3</a>\u001b[0m X_train, y_train \u001b[39m=\u001b[39m oversample\u001b[39m.\u001b[39;49mfit_resample(X_train, y_train)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.5/envs/masters_thesis/lib/python3.10/site-packages/imblearn/base.py:83\u001b[0m, in \u001b[0;36mSamplerMixin.fit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     77\u001b[0m X, y, binarize_y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_X_y(X, y)\n\u001b[1;32m     79\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msampling_strategy_ \u001b[39m=\u001b[39m check_sampling_strategy(\n\u001b[1;32m     80\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msampling_strategy, y, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampling_type\n\u001b[1;32m     81\u001b[0m )\n\u001b[0;32m---> 83\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_resample(X, y)\n\u001b[1;32m     85\u001b[0m y_ \u001b[39m=\u001b[39m (\n\u001b[1;32m     86\u001b[0m     label_binarize(output[\u001b[39m1\u001b[39m], classes\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39munique(y)) \u001b[39mif\u001b[39;00m binarize_y \u001b[39melse\u001b[39;00m output[\u001b[39m1\u001b[39m]\n\u001b[1;32m     87\u001b[0m )\n\u001b[1;32m     89\u001b[0m X_, y_ \u001b[39m=\u001b[39m arrays_transformer\u001b[39m.\u001b[39mtransform(output[\u001b[39m0\u001b[39m], y_)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.5/envs/masters_thesis/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py:320\u001b[0m, in \u001b[0;36mSMOTE._fit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[39mif\u001b[39;00m n_samples \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    319\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m--> 320\u001b[0m target_class_indices \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mflatnonzero(y \u001b[39m==\u001b[39;49m class_sample)\n\u001b[1;32m    321\u001b[0m X_class \u001b[39m=\u001b[39m _safe_indexing(X, target_class_indices)\n\u001b[1;32m    323\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnn_k_\u001b[39m.\u001b[39mfit(X_class)\n",
      "File \u001b[0;32m<__array_function__ internals>:177\u001b[0m, in \u001b[0;36mflatnonzero\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "oversample = SMOTE(k_neighbors=1)\n",
    "X_train, y_train = oversample.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C2    38758\n",
       "D2    38758\n",
       "D1    38758\n",
       "G     38758\n",
       "B3    38758\n",
       "E1    38758\n",
       "C1    38758\n",
       "C3    38758\n",
       "F     38758\n",
       "E2    38758\n",
       "B2    38758\n",
       "B1    38758\n",
       "A3    38758\n",
       "A2    38758\n",
       "A1    38758\n",
       "Name: EnergyRating, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "D1    16526\n",
       "C3    16099\n",
       "D2    14679\n",
       "C2    14249\n",
       "C1    10427\n",
       "G      8955\n",
       "E1     8807\n",
       "F      7441\n",
       "E2     7154\n",
       "B3     5989\n",
       "B2     2191\n",
       "B1      752\n",
       "A3      262\n",
       "A2       22\n",
       "Name: EnergyRating, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier()\n",
    "x = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the forest's predict method on the test data\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          A2       0.91      0.45      0.61        22\n",
      "          A3       0.72      0.76      0.74       262\n",
      "          B1       0.64      0.67      0.65       752\n",
      "          B2       0.61      0.59      0.60      2191\n",
      "          B3       0.59      0.60      0.59      5989\n",
      "          C1       0.57      0.56      0.57     10427\n",
      "          C2       0.56      0.56      0.56     14249\n",
      "          C3       0.54      0.54      0.54     16099\n",
      "          D1       0.56      0.55      0.56     16526\n",
      "          D2       0.56      0.57      0.56     14679\n",
      "          E1       0.46      0.45      0.46      8807\n",
      "          E2       0.45      0.45      0.45      7154\n",
      "           F       0.55      0.56      0.55      7441\n",
      "           G       0.79      0.84      0.81      8955\n",
      "\n",
      "    accuracy                           0.57    113553\n",
      "   macro avg       0.61      0.58      0.59    113553\n",
      "weighted avg       0.57      0.57      0.57    113553\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred)) #classification report from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.DataFrame(clf.feature_importances_, index=X_train.columns).sort_values(by=0, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TotalDeliveredEnergy</th>\n",
       "      <td>0.19592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YearofConstruction</th>\n",
       "      <td>0.17473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GroundFloorArea(sq m)</th>\n",
       "      <td>0.15796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>InsulationThickness</th>\n",
       "      <td>0.09556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NoOfSidesSheltered_2.0</th>\n",
       "      <td>0.01861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VentilationMethod_Natural vent.</th>\n",
       "      <td>0.01682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VentilationMethod_Bal.whole mech.vent heat recvr</th>\n",
       "      <td>0.01456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>StructureType_Masonry</th>\n",
       "      <td>0.01414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NoOfSidesSheltered_3.0</th>\n",
       "      <td>0.01343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DwellingTypeDescr_Detached house</th>\n",
       "      <td>0.01242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       0\n",
       "TotalDeliveredEnergy                             0.19592\n",
       "YearofConstruction                               0.17473\n",
       "GroundFloorArea(sq m)                            0.15796\n",
       "InsulationThickness                              0.09556\n",
       "NoOfSidesSheltered_2.0                           0.01861\n",
       "VentilationMethod_Natural vent.                  0.01682\n",
       "VentilationMethod_Bal.whole mech.vent heat recvr 0.01456\n",
       "StructureType_Masonry                            0.01414\n",
       "NoOfSidesSheltered_3.0                           0.01343\n",
       "DwellingTypeDescr_Detached house                 0.01242"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.iloc[0:10, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5670832122445025\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "D1    2162\n",
       "C3    2081\n",
       "D2    1966\n",
       "C2    1890\n",
       "C1    1342\n",
       "G     1239\n",
       "E1    1167\n",
       "E2     990\n",
       "F      930\n",
       "B3     786\n",
       "B2     306\n",
       "B1      92\n",
       "A3      46\n",
       "A2       3\n",
       "Name: EnergyRating, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "criterion = ['gini', 'entropy', 'log_loss']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'criterion': criterion,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestClassifier()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 10, cv = 3, random_state=2814, verbose=2, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators= 1200,\n",
    "min_samples_split=2,\n",
    "min_samples_leaf=1,\n",
    "max_depth=70,\n",
    "criterion='entropy',\n",
    "bootstrap=True)\n",
    "\n",
    "rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\"\"\"\n",
    "Use your classification model to predict some labels\n",
    "Then, plot confusion matrix and classification report using below code\n",
    "y_test: real labels\n",
    "y_pred: predicted model labels\n",
    "\"\"\"\n",
    "labels = ['A1', 'A2', 'A3', 'B1', 'B2', 'B3', 'C1', 'C2', 'C3', 'D1', 'D2', 'E1', 'E2', 'F', 'G'] \n",
    "print(classification_report(y_test, y_pred)) #classification report from sklearn\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred, labels=labels)\n",
    "plt.imshow(cnf_matrix, cmap=plt.cm.Blues) #plot confusion matrix grid\n",
    "threshold = cnf_matrix.max() / 2 #threshold to define text color\n",
    "for i in range(cnf_matrix.shape[0]): #print text in grid\n",
    "    for j in range(cnf_matrix.shape[1]): \n",
    "        plt.text(j, i, cnf_matrix[i,j], color=\"w\" if cnf_matrix[i,j] > threshold else 'black')\n",
    "tick_marks = np.arange(len(labels)) #define labeling spacing based on number of classes\n",
    "plt.xticks(tick_marks, labels, rotation=45)\n",
    "plt.yticks(tick_marks, labels)\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.colorbar()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = clf.feature_importances_\n",
    "# summarize feature importance\n",
    "for i,v in enumerate(importance):\n",
    "    print('Feature: {}, Score: {}'.format(i,v))\n",
    "# plot feature importance\n",
    "plt.bar([x for x in range(len(importance))], importance)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=10)\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the forest's predict method on the test data\n",
    "y_pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\"\"\"\n",
    "Use your classification model to predict some labels\n",
    "Then, plot confusion matrix and classification report using below code\n",
    "y_test: real labels\n",
    "y_pred: predicted model labels\n",
    "\"\"\"\n",
    "labels = ['A1', 'A2', 'A3', 'B1', 'B2', 'B3', 'C1', 'C2', 'C3', 'D1', 'D2', 'E1', 'E2', 'F', 'G'] \n",
    "print(classification_report(y_test, y_pred)) #classification report from sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as imbpipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.datasets import make_classification, load_breast_cancer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in our cleaned up SEAI data\n",
    "seai_dropped_na = pd.read_csv('../data/interim/1_seai_dropped_na.csv')\n",
    "seai_dropped_na = seai_dropped_na.drop('BerRating', axis = 1)\n",
    "seai_dropped_na = seai_dropped_na.drop('CO2Rating', axis = 1)\n",
    "seai_dropped_na['NoOfSidesSheltered'] = seai_dropped_na['NoOfSidesSheltered'].astype('category')\n",
    "new_cols = [col for col in seai_dropped_na.columns if col != 'EnergyRating'] + ['EnergyRating']\n",
    "seai_dropped_na = seai_dropped_na[new_cols]\n",
    "\n",
    "del(new_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rpy2 import robjects\n",
    "from rpy2.robjects import pandas2ri\n",
    "pandas2ri.activate()\n",
    "from rpy2.robjects.packages import importr # import R's \"base\" package\n",
    "base = importr('base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seai_dropped_na_r = robjects.conversion.py2rpy(seai_dropped_na)\n",
    "robjects.globalenv[\"seai_dropped_na_r\"] = seai_dropped_na_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base.summary(seai_dropped_na_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robjects.r('''\n",
    "sample_size = 20000\n",
    "set.seed(1)\n",
    "idxs = sample(1:nrow(seai_dropped_na_r),sample_size,replace=F)\n",
    "subsample = seai_dropped_na_r[idxs,]\n",
    "pvalues = list()\n",
    "for (col in names(seai_dropped_na_r)) {\n",
    "  if (class(seai_dropped_na_r[,col]) %in% c(\"numeric\",\"integer\")) {\n",
    "    # Numeric variable. Using Kolmogorov-Smirnov test\n",
    "    \n",
    "    pvalues[[col]] = ks.test(subsample[[col]],seai_dropped_na_r[[col]])$p.value\n",
    "    \n",
    "  } else {\n",
    "    \n",
    "    \n",
    "  }\n",
    "}\n",
    "\n",
    "pvalues''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/a/52935270/5923619\n",
    "# One Hot Encodes our categorical feature and binds it to the original dataset\n",
    "def encode_and_bind(original_dataframe, feature_to_encode):\n",
    "    dummies = pd.get_dummies(original_dataframe[[feature_to_encode]])\n",
    "    res = pd.concat([original_dataframe, dummies], axis=1)\n",
    "    return(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot Encode all of our categorical features\n",
    "seai_dropped_na_scaled = encode_and_bind(seai_dropped_na, 'CountyName')\n",
    "seai_dropped_na_scaled = encode_and_bind(seai_dropped_na_scaled, 'DwellingTypeDescr')\n",
    "seai_dropped_na_scaled = encode_and_bind(seai_dropped_na_scaled, 'MainSpaceHeatingFuel')\n",
    "seai_dropped_na_scaled = encode_and_bind(seai_dropped_na_scaled, 'MainWaterHeatingFuel')\n",
    "seai_dropped_na_scaled = encode_and_bind(seai_dropped_na_scaled, 'VentilationMethod')\n",
    "seai_dropped_na_scaled = encode_and_bind(seai_dropped_na_scaled, 'StructureType')\n",
    "seai_dropped_na_scaled = encode_and_bind(seai_dropped_na_scaled, 'InsulationType')\n",
    "seai_dropped_na_scaled = encode_and_bind(seai_dropped_na_scaled, 'MainSpaceHeatingFuel')\n",
    "seai_dropped_na_scaled = encode_and_bind(seai_dropped_na_scaled, 'MainWaterHeatingFuel')\n",
    "seai_dropped_na_scaled = encode_and_bind(seai_dropped_na_scaled, 'NoOfSidesSheltered')\n",
    "\n",
    "seai_dropped_na_scaled\n",
    "# Dropping the unencoded columns for now\n",
    "seai_dropped_na_scaled = seai_dropped_na_scaled.drop(['CountyName', 'DwellingTypeDescr', 'VentilationMethod', 'StructureType', 'InsulationType', 'MainSpaceHeatingFuel',\t'MainWaterHeatingFuel',\t'NoOfSidesSheltered'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = seai_dropped_na_scaled.iloc[:, :-1] # Independent Variables\n",
    "y = seai_dropped_na_scaled.iloc[:, -1] # Dependent Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Split into train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=3)\n",
    "\n",
    "# 3. Perform the scaling on the data\n",
    "# 4. Fit a model\n",
    "# 5. Do stratified k fold sampling\n",
    "# 6. GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = QuantileTransformer()\n",
    "num_cols = ['YearofConstruction', 'GroundFloorArea(sq m)', 'TotalDeliveredEnergy', 'InsulationThickness']\n",
    "seai_dropped_na_scaled = seai_dropped_na.copy()\n",
    "seai_dropped_na_scaled[num_cols] = scaler.fit_transform(seai_dropped_na[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cols = [col for col in seai_dropped_na_scaled.columns if col != 'EnergyRating'] + ['EnergyRating']\n",
    "seai_dropped_na_scaled = seai_dropped_na_scaled[new_cols]\n",
    "\n",
    "del(new_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "oversample = SMOTE(k_neighbors=1)\n",
    "X, y = oversample.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stratified_kfold = StratifiedKFold(n_splits=2,\n",
    "                                       shuffle=True,\n",
    "                                       random_state=1)\n",
    "    \n",
    "param_grid = {'classifier__C':[0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n",
    "grid_search = GridSearchCV(estimator=pipeline,\n",
    "                           param_grid=param_grid,\n",
    "                           scoring='roc_auc',\n",
    "                           cv=stratified_kfold,\n",
    "                           n_jobs=-1)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "cv_score = grid_search.best_score_\n",
    "test_score = grid_search.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "ecf9425976ca1d495f6ff342e01edb9b99409cdaa6c55166a5169aaab36ca909"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
