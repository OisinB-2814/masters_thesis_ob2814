{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow import keras\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from tensorflow.keras.layers import LeakyReLU, Dense, BatchNormalization\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import load\n",
    "X_train = load('../data/interim//Design/X_train.npy')\n",
    "X_test = load('../data/interim/Design/X_test.npy')\n",
    "y_train = load('../data/interim/Design/y_train.npy')\n",
    "y_test = load('../data/interim/Design/y_test.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "yle = LabelEncoder()\n",
    "y_train = yle.fit_transform(y_train)\n",
    "y_test = yle.transform(y_test)\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "y_train = to_categorical(y_train, 15)\n",
    "y_test = to_categorical(y_test, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "def baseline_model():\n",
    "    # Create model here\n",
    "    model = Sequential()\n",
    "    model.add(Dense(15, input_dim = 13, activation = 'relu')) # Rectified Linear Unit Activation Function\n",
    "    model.add(Dense(15, activation = 'relu'))\n",
    "    model.add(Dense(11, activation = 'softmax')) # Softmax for multi-class classification\n",
    "    # Compile model here\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy', keras.metrics.Precision(), keras.metrics.Recall()])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-30 21:35:52.691116: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "365/365 [==============================] - ETA: 0s - loss: 1.8992 - accuracy: 0.2890 - precision_1: 0.6101 - recall_1: 0.0842"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-30 21:36:08.294226: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "365/365 [==============================] - 18s 46ms/step - loss: 1.8992 - accuracy: 0.2890 - precision_1: 0.6101 - recall_1: 0.0842 - val_loss: 1.7944 - val_accuracy: 0.3150 - val_precision_1: 0.6119 - val_recall_1: 0.0690\n",
      "Epoch 2/50\n",
      "365/365 [==============================] - 16s 45ms/step - loss: 1.5691 - accuracy: 0.3829 - precision_1: 0.6580 - recall_1: 0.1486 - val_loss: 1.5799 - val_accuracy: 0.3535 - val_precision_1: 0.6261 - val_recall_1: 0.0617\n",
      "Epoch 3/50\n",
      "365/365 [==============================] - 19s 53ms/step - loss: 1.3626 - accuracy: 0.4599 - precision_1: 0.6762 - recall_1: 0.2219 - val_loss: 1.1403 - val_accuracy: 0.6199 - val_precision_1: 0.8084 - val_recall_1: 0.2791\n",
      "Epoch 4/50\n",
      "365/365 [==============================] - 21s 57ms/step - loss: 1.1957 - accuracy: 0.5227 - precision_1: 0.6811 - recall_1: 0.3304 - val_loss: 1.4566 - val_accuracy: 0.3060 - val_precision_1: 0.4067 - val_recall_1: 0.2039\n",
      "Epoch 5/50\n",
      "365/365 [==============================] - 21s 56ms/step - loss: 1.0687 - accuracy: 0.5697 - precision_1: 0.6944 - recall_1: 0.4222 - val_loss: 1.0846 - val_accuracy: 0.5434 - val_precision_1: 0.7025 - val_recall_1: 0.4036\n",
      "Epoch 6/50\n",
      "365/365 [==============================] - 24s 66ms/step - loss: 1.0405 - accuracy: 0.5975 - precision_1: 0.7123 - recall_1: 0.4624 - val_loss: 0.8469 - val_accuracy: 0.7225 - val_precision_1: 0.8244 - val_recall_1: 0.5879\n",
      "Epoch 7/50\n",
      "365/365 [==============================] - 25s 69ms/step - loss: 1.0223 - accuracy: 0.6058 - precision_1: 0.7095 - recall_1: 0.4861 - val_loss: 0.8515 - val_accuracy: 0.6826 - val_precision_1: 0.7884 - val_recall_1: 0.5771\n",
      "Epoch 8/50\n",
      "365/365 [==============================] - 24s 65ms/step - loss: 0.9085 - accuracy: 0.6414 - precision_1: 0.7240 - recall_1: 0.5552 - val_loss: 1.0867 - val_accuracy: 0.5233 - val_precision_1: 0.6001 - val_recall_1: 0.4682\n",
      "Epoch 9/50\n",
      "365/365 [==============================] - 24s 66ms/step - loss: 0.8819 - accuracy: 0.6535 - precision_1: 0.7299 - recall_1: 0.5758 - val_loss: 0.9370 - val_accuracy: 0.6062 - val_precision_1: 0.7065 - val_recall_1: 0.5077\n",
      "Epoch 10/50\n",
      "365/365 [==============================] - 25s 70ms/step - loss: 0.8629 - accuracy: 0.6669 - precision_1: 0.7427 - recall_1: 0.5895 - val_loss: 0.7864 - val_accuracy: 0.7122 - val_precision_1: 0.7947 - val_recall_1: 0.6314\n",
      "Epoch 11/50\n",
      "365/365 [==============================] - 25s 67ms/step - loss: 0.8311 - accuracy: 0.6775 - precision_1: 0.7483 - recall_1: 0.6079 - val_loss: 1.0505 - val_accuracy: 0.5446 - val_precision_1: 0.6265 - val_recall_1: 0.4655\n",
      "Epoch 12/50\n",
      "365/365 [==============================] - 25s 68ms/step - loss: 0.8293 - accuracy: 0.6818 - precision_1: 0.7543 - recall_1: 0.6104 - val_loss: 0.8310 - val_accuracy: 0.6649 - val_precision_1: 0.7421 - val_recall_1: 0.6026\n",
      "Epoch 13/50\n",
      "365/365 [==============================] - 25s 69ms/step - loss: 0.7689 - accuracy: 0.7012 - precision_1: 0.7657 - recall_1: 0.6391 - val_loss: 0.6754 - val_accuracy: 0.7684 - val_precision_1: 0.8410 - val_recall_1: 0.7030\n",
      "Epoch 14/50\n",
      "365/365 [==============================] - 24s 67ms/step - loss: 0.7663 - accuracy: 0.7042 - precision_1: 0.7677 - recall_1: 0.6421 - val_loss: 0.8268 - val_accuracy: 0.6636 - val_precision_1: 0.7332 - val_recall_1: 0.6053\n",
      "Epoch 15/50\n",
      "365/365 [==============================] - 24s 66ms/step - loss: 0.7468 - accuracy: 0.7112 - precision_1: 0.7737 - recall_1: 0.6515 - val_loss: 0.6464 - val_accuracy: 0.7760 - val_precision_1: 0.8445 - val_recall_1: 0.7116\n",
      "Epoch 16/50\n",
      "365/365 [==============================] - 24s 65ms/step - loss: 0.7368 - accuracy: 0.7157 - precision_1: 0.7766 - recall_1: 0.6575 - val_loss: 0.6644 - val_accuracy: 0.7617 - val_precision_1: 0.8282 - val_recall_1: 0.6970\n",
      "Epoch 17/50\n",
      "365/365 [==============================] - 24s 65ms/step - loss: 0.7286 - accuracy: 0.7191 - precision_1: 0.7796 - recall_1: 0.6623 - val_loss: 0.7952 - val_accuracy: 0.6766 - val_precision_1: 0.7455 - val_recall_1: 0.6221\n",
      "Epoch 18/50\n",
      "365/365 [==============================] - 24s 65ms/step - loss: 0.7280 - accuracy: 0.7231 - precision_1: 0.7842 - recall_1: 0.6646 - val_loss: 0.6926 - val_accuracy: 0.7444 - val_precision_1: 0.8064 - val_recall_1: 0.6897\n",
      "Epoch 19/50\n",
      "365/365 [==============================] - 24s 65ms/step - loss: 0.7010 - accuracy: 0.7304 - precision_1: 0.7876 - recall_1: 0.6766 - val_loss: 0.7015 - val_accuracy: 0.7285 - val_precision_1: 0.7987 - val_recall_1: 0.6747\n",
      "Epoch 20/50\n",
      "365/365 [==============================] - 24s 66ms/step - loss: 0.6906 - accuracy: 0.7349 - precision_1: 0.7907 - recall_1: 0.6827 - val_loss: 0.8562 - val_accuracy: 0.6442 - val_precision_1: 0.7263 - val_recall_1: 0.5669\n",
      "Epoch 21/50\n",
      "365/365 [==============================] - 24s 66ms/step - loss: 0.6789 - accuracy: 0.7406 - precision_1: 0.7975 - recall_1: 0.6881 - val_loss: 0.6940 - val_accuracy: 0.7368 - val_precision_1: 0.8045 - val_recall_1: 0.6783\n",
      "Epoch 22/50\n",
      "365/365 [==============================] - 24s 66ms/step - loss: 0.6614 - accuracy: 0.7480 - precision_1: 0.8020 - recall_1: 0.6976 - val_loss: 0.7159 - val_accuracy: 0.7220 - val_precision_1: 0.7838 - val_recall_1: 0.6680\n",
      "Epoch 23/50\n",
      "365/365 [==============================] - 24s 67ms/step - loss: 0.6639 - accuracy: 0.7462 - precision_1: 0.7998 - recall_1: 0.6965 - val_loss: 0.7030 - val_accuracy: 0.7243 - val_precision_1: 0.7870 - val_recall_1: 0.6725\n",
      "Epoch 24/50\n",
      "365/365 [==============================] - 25s 67ms/step - loss: 0.6675 - accuracy: 0.7457 - precision_1: 0.8000 - recall_1: 0.6949 - val_loss: 0.6186 - val_accuracy: 0.7847 - val_precision_1: 0.8470 - val_recall_1: 0.7257\n",
      "Epoch 25/50\n",
      "365/365 [==============================] - 25s 67ms/step - loss: 0.6681 - accuracy: 0.7484 - precision_1: 0.8035 - recall_1: 0.6970 - val_loss: 0.6388 - val_accuracy: 0.7684 - val_precision_1: 0.8322 - val_recall_1: 0.7138\n",
      "Epoch 26/50\n",
      "365/365 [==============================] - 25s 68ms/step - loss: 0.6507 - accuracy: 0.7521 - precision_1: 0.8050 - recall_1: 0.7035 - val_loss: 0.6534 - val_accuracy: 0.7601 - val_precision_1: 0.8223 - val_recall_1: 0.7044\n",
      "Epoch 27/50\n",
      "365/365 [==============================] - 25s 68ms/step - loss: 0.6336 - accuracy: 0.7603 - precision_1: 0.8116 - recall_1: 0.7127 - val_loss: 0.6797 - val_accuracy: 0.7380 - val_precision_1: 0.7978 - val_recall_1: 0.6904\n",
      "Epoch 28/50\n",
      "365/365 [==============================] - 25s 68ms/step - loss: 0.6474 - accuracy: 0.7536 - precision_1: 0.8069 - recall_1: 0.7054 - val_loss: 0.5943 - val_accuracy: 0.7921 - val_precision_1: 0.8497 - val_recall_1: 0.7424\n",
      "Epoch 29/50\n",
      "365/365 [==============================] - 25s 68ms/step - loss: 0.6309 - accuracy: 0.7603 - precision_1: 0.8111 - recall_1: 0.7136 - val_loss: 0.7463 - val_accuracy: 0.6951 - val_precision_1: 0.7582 - val_recall_1: 0.6519\n",
      "Epoch 30/50\n",
      "365/365 [==============================] - 25s 69ms/step - loss: 0.6224 - accuracy: 0.7631 - precision_1: 0.8136 - recall_1: 0.7174 - val_loss: 0.7765 - val_accuracy: 0.6852 - val_precision_1: 0.7458 - val_recall_1: 0.6347\n",
      "Epoch 31/50\n",
      "365/365 [==============================] - 26s 70ms/step - loss: 0.6312 - accuracy: 0.7614 - precision_1: 0.8125 - recall_1: 0.7146 - val_loss: 0.7642 - val_accuracy: 0.6867 - val_precision_1: 0.7536 - val_recall_1: 0.6454\n",
      "Epoch 32/50\n",
      "365/365 [==============================] - 26s 71ms/step - loss: 0.6146 - accuracy: 0.7671 - precision_1: 0.8170 - recall_1: 0.7213 - val_loss: 0.6951 - val_accuracy: 0.7317 - val_precision_1: 0.7920 - val_recall_1: 0.6870\n",
      "Epoch 33/50\n",
      "365/365 [==============================] - 27s 74ms/step - loss: 0.6061 - accuracy: 0.7695 - precision_1: 0.8184 - recall_1: 0.7251 - val_loss: 0.7802 - val_accuracy: 0.6840 - val_precision_1: 0.7378 - val_recall_1: 0.6407\n",
      "Epoch 34/50\n",
      "365/365 [==============================] - 26s 72ms/step - loss: 0.6106 - accuracy: 0.7705 - precision_1: 0.8197 - recall_1: 0.7253 - val_loss: 0.9536 - val_accuracy: 0.6008 - val_precision_1: 0.6507 - val_recall_1: 0.5630\n",
      "Epoch 35/50\n",
      "365/365 [==============================] - 28s 77ms/step - loss: 0.6125 - accuracy: 0.7684 - precision_1: 0.8176 - recall_1: 0.7234 - val_loss: 0.6000 - val_accuracy: 0.7852 - val_precision_1: 0.8454 - val_recall_1: 0.7294\n",
      "Epoch 36/50\n",
      "365/365 [==============================] - 27s 73ms/step - loss: 0.6264 - accuracy: 0.7640 - precision_1: 0.8155 - recall_1: 0.7173 - val_loss: 0.6681 - val_accuracy: 0.7486 - val_precision_1: 0.8125 - val_recall_1: 0.6914\n",
      "Epoch 37/50\n",
      "365/365 [==============================] - 27s 73ms/step - loss: 0.6034 - accuracy: 0.7733 - precision_1: 0.8227 - recall_1: 0.7285 - val_loss: 0.7589 - val_accuracy: 0.6992 - val_precision_1: 0.7594 - val_recall_1: 0.6494\n",
      "Epoch 38/50\n",
      "365/365 [==============================] - 26s 72ms/step - loss: 0.6075 - accuracy: 0.7718 - precision_1: 0.8216 - recall_1: 0.7264 - val_loss: 0.6156 - val_accuracy: 0.7862 - val_precision_1: 0.8521 - val_recall_1: 0.7246\n",
      "Epoch 39/50\n",
      "365/365 [==============================] - 26s 72ms/step - loss: 0.5939 - accuracy: 0.7753 - precision_1: 0.8235 - recall_1: 0.7319 - val_loss: 0.5835 - val_accuracy: 0.7925 - val_precision_1: 0.8450 - val_recall_1: 0.7467\n",
      "Epoch 40/50\n",
      "365/365 [==============================] - 26s 71ms/step - loss: 0.5834 - accuracy: 0.7796 - precision_1: 0.8261 - recall_1: 0.7377 - val_loss: 1.2084 - val_accuracy: 0.4983 - val_precision_1: 0.5537 - val_recall_1: 0.4483\n",
      "Epoch 41/50\n",
      "365/365 [==============================] - 26s 71ms/step - loss: 0.5812 - accuracy: 0.7814 - precision_1: 0.8285 - recall_1: 0.7382 - val_loss: 0.6234 - val_accuracy: 0.7671 - val_precision_1: 0.8191 - val_recall_1: 0.7220\n",
      "Epoch 42/50\n",
      "365/365 [==============================] - 26s 71ms/step - loss: 0.5799 - accuracy: 0.7815 - precision_1: 0.8279 - recall_1: 0.7397 - val_loss: 0.5826 - val_accuracy: 0.7919 - val_precision_1: 0.8451 - val_recall_1: 0.7457\n",
      "Epoch 43/50\n",
      "365/365 [==============================] - 26s 71ms/step - loss: 0.5754 - accuracy: 0.7823 - precision_1: 0.8283 - recall_1: 0.7408 - val_loss: 0.6032 - val_accuracy: 0.7837 - val_precision_1: 0.8310 - val_recall_1: 0.7425\n",
      "Epoch 44/50\n",
      "365/365 [==============================] - 26s 71ms/step - loss: 0.5848 - accuracy: 0.7803 - precision_1: 0.8276 - recall_1: 0.7376 - val_loss: 0.5749 - val_accuracy: 0.7961 - val_precision_1: 0.8456 - val_recall_1: 0.7523\n",
      "Epoch 45/50\n",
      "365/365 [==============================] - 28s 76ms/step - loss: 0.5774 - accuracy: 0.7813 - precision_1: 0.8272 - recall_1: 0.7399 - val_loss: 0.6809 - val_accuracy: 0.7369 - val_precision_1: 0.7997 - val_recall_1: 0.6935\n",
      "Epoch 46/50\n",
      "365/365 [==============================] - 29s 80ms/step - loss: 0.5489 - accuracy: 0.7932 - precision_1: 0.8369 - recall_1: 0.7534 - val_loss: 0.5933 - val_accuracy: 0.7819 - val_precision_1: 0.8290 - val_recall_1: 0.7466\n",
      "Epoch 47/50\n",
      "365/365 [==============================] - 28s 77ms/step - loss: 0.5636 - accuracy: 0.7876 - precision_1: 0.8324 - recall_1: 0.7472 - val_loss: 0.6898 - val_accuracy: 0.7364 - val_precision_1: 0.7883 - val_recall_1: 0.6957\n",
      "Epoch 48/50\n",
      "365/365 [==============================] - 28s 75ms/step - loss: 0.5629 - accuracy: 0.7861 - precision_1: 0.8301 - recall_1: 0.7466 - val_loss: 0.6087 - val_accuracy: 0.7798 - val_precision_1: 0.8401 - val_recall_1: 0.7299\n",
      "Epoch 49/50\n",
      "365/365 [==============================] - 28s 77ms/step - loss: 0.5368 - accuracy: 0.7988 - precision_1: 0.8409 - recall_1: 0.7606 - val_loss: 0.5571 - val_accuracy: 0.8015 - val_precision_1: 0.8509 - val_recall_1: 0.7601\n",
      "Epoch 50/50\n",
      "365/365 [==============================] - 28s 76ms/step - loss: 0.5815 - accuracy: 0.7809 - precision_1: 0.8280 - recall_1: 0.7385 - val_loss: 0.8999 - val_accuracy: 0.6286 - val_precision_1: 0.6750 - val_recall_1: 0.5907\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KerasClassifier(\n",
       "\tmodel=&lt;function baseline_model at 0x2e798a9d0&gt;\n",
       "\tbuild_fn=None\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=rmsprop\n",
       "\tloss=None\n",
       "\tmetrics=None\n",
       "\tbatch_size=2056\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=1\n",
       "\tcallbacks=None\n",
       "\tvalidation_split=0.0\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=50\n",
       "\tclass_weight=None\n",
       ")</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KerasClassifier</label><div class=\"sk-toggleable__content\"><pre>KerasClassifier(\n",
       "\tmodel=&lt;function baseline_model at 0x2e798a9d0&gt;\n",
       "\tbuild_fn=None\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=rmsprop\n",
       "\tloss=None\n",
       "\tmetrics=None\n",
       "\tbatch_size=2056\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=1\n",
       "\tcallbacks=None\n",
       "\tvalidation_split=0.0\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=50\n",
       "\tclass_weight=None\n",
       ")</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KerasClassifier(\n",
       "\tmodel=<function baseline_model at 0x2e798a9d0>\n",
       "\tbuild_fn=None\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=rmsprop\n",
       "\tloss=None\n",
       "\tmetrics=None\n",
       "\tbatch_size=2056\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=1\n",
       "\tcallbacks=None\n",
       "\tvalidation_split=0.0\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=50\n",
       "\tclass_weight=None\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator = KerasClassifier(model=baseline_model, epochs=50, batch_size=1024)\n",
    "estimator.fit(X_train, y_train, validation_data = ((X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 1s 12ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.16      0.69      0.26       252\n",
      "           1       0.84      0.82      0.83      8648\n",
      "           2       0.88      0.79      0.83     10239\n",
      "           3       0.47      0.82      0.59      3052\n",
      "           4       0.50      0.72      0.59      6563\n",
      "           5       0.58      0.71      0.64     15594\n",
      "           6       0.62      0.62      0.62     22757\n",
      "           7       0.61      0.60      0.61     24906\n",
      "           8       0.58      0.55      0.57     23637\n",
      "           9       0.60      0.55      0.57     22871\n",
      "          10       0.65      0.56      0.60     19637\n",
      "          11       0.54      0.56      0.55     11326\n",
      "          12       0.48      0.52      0.50      8956\n",
      "          13       0.65      0.56      0.60      9269\n",
      "          14       0.98      0.80      0.88     13363\n",
      "\n",
      "   micro avg       0.63      0.63      0.63    201070\n",
      "   macro avg       0.61      0.66      0.62    201070\n",
      "weighted avg       0.64      0.63      0.63    201070\n",
      " samples avg       0.63      0.63      0.63    201070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = estimator.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit ('NN')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a65ca7f3459d077aa20279ab33dd397a7d6c76a6aca1cdcc25b5a2615eafe111"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
